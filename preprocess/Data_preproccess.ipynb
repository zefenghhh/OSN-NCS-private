{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mat to png (Wei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mat to avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "mat_contents = sio.loadmat('D:\\\\project\\\\Weizmann\\\\aligned_masks_dev.mat') \n",
    "aligned_masks = mat_contents['masks']\n",
    "video_dir = 'D:\\\\project\\\\Weizmann\\\\700_700_avi_dev'\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "for name in aligned_masks.dtype.names:\n",
    "    mask_data = aligned_masks[name][0, 0]\n",
    "    video_filename = os.path.join(video_dir, f\"{name}.avi\")\n",
    "    out = cv2.VideoWriter(video_filename, fourcc, 30.0, (700, 700), isColor=False)\n",
    "\n",
    "    for i in range(mask_data.shape[2]):\n",
    "        frame = mask_data[:, :, i].astype(np.uint8) * 255       \n",
    "        top_padding = (180 - 144) // 2\n",
    "        bottom_padding = 180 - 144 - top_padding\n",
    "\n",
    "        frame_padded = cv2.copyMakeBorder(frame, top_padding, bottom_padding, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        frame = cv2.resize(frame_padded, (700, 700))\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(\"All videos have been saved in:\", video_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avi to event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import sys\n",
    "sys.path.append(r\"D:\\\\my_software\\\\event_camera\\\\Prophesee\\\\lib\\\\python3\\\\site-packages\\\\\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from metavision_core_ml.video_to_event.simulator import EventSimulator\n",
    "from metavision_core_ml.data.video_stream import TimedVideoStream\n",
    "\n",
    "def video_to_events(video_path, output_path):\n",
    "    height, width = 700, 700\n",
    "    stream = TimedVideoStream(video_path)\n",
    "\n",
    "    C = 0.5  \n",
    "    refractory_period = 10000  \n",
    "    cutoff_hz = 30  \n",
    "    sigma_threshold = 0 \n",
    "    shot_noise_rate_hz = 0 \n",
    "\n",
    "    simulator = EventSimulator(height, width, C, C, refractory_period, cutoff_hz=cutoff_hz, \n",
    "                               sigma_threshold=sigma_threshold, shot_noise_rate_hz=shot_noise_rate_hz)\n",
    "\n",
    "    events = []\n",
    "    for img, ts in stream:\n",
    "        total_events = simulator.image_callback(img.squeeze(), ts)\n",
    "        if total_events > 0:\n",
    "            frame_events = simulator.get_events()\n",
    "            events.append(frame_events)\n",
    "            simulator.flush_events()  \n",
    "\n",
    "    if events:\n",
    "        events = np.concatenate(events)\n",
    "        np.save(output_path, events)  \n",
    "\n",
    "def convert_video(video_path, output_path):\n",
    "    video_to_events(video_path, output_path)\n",
    "\n",
    "def convert_videos_to_events(input_folder, output_folder):\n",
    "    existing_files = os.listdir(output_folder)\n",
    "    videos_to_convert = []\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".avi\"):\n",
    "            video_path = os.path.join(input_folder, filename)\n",
    "            event_filename = filename.replace(\".avi\", \".npy\")\n",
    "            output_path = os.path.join(output_folder, event_filename)\n",
    "            if event_filename not in existing_files:\n",
    "                videos_to_convert.append((video_path, output_path))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_video = {executor.submit(convert_video, video_path, output_path): (video_path, output_path) for video_path, output_path in videos_to_convert}\n",
    "        for future in tqdm(as_completed(future_to_video), total=len(videos_to_convert), desc=\"Converting videos\"):\n",
    "            try:\n",
    "                future.result()  \n",
    "            except Exception as exc:\n",
    "                video_path, output_path = future_to_video[future]\n",
    "                print(f'Error processing {video_path}: {exc}')\n",
    "\n",
    "dev_input_folder = \"D:\\\\project\\\\Weizmann\\\\700_700_avi_dev\"\n",
    "dev_output_folder = \"D:\\\\project\\\\Weizmann\\\\700_700_npy_dev\"\n",
    "\n",
    "\n",
    "os.makedirs(dev_output_folder, exist_ok=True)\n",
    "convert_videos_to_events(dev_input_folder, dev_output_folder)\n",
    "# convert_videos_to_events(train_input_folder, train_output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## event to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "folder_path = \"D:\\\\project\\\\Weizmann\\\\700_700_npy_dev\"\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
    "\n",
    "# figure size\n",
    "xx = 700\n",
    "yy = 700\n",
    "\n",
    "for file in files:\n",
    "    events = np.load(os.path.join(folder_path, file))\n",
    "\n",
    "    dtype = [('x', np.int16), ('y', np.int16), ('polarity', np.int8), ('timestamp', np.int32)]\n",
    "    filtered_events = np.array([tuple(event) for event in events], dtype=dtype)\n",
    "\n",
    "    delta_t = 1000000\n",
    "    total_time = filtered_events[-1]['timestamp']\n",
    "    num_frames = total_time // delta_t\n",
    "    remainder = total_time % delta_t\n",
    "    if remainder > (delta_t/2):\n",
    "        num_frames += 1\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        start_time = i * delta_t\n",
    "        end_time = (i + 1) * delta_t\n",
    "        time_filtered_events = filtered_events[(filtered_events['timestamp'] > start_time) & (filtered_events['timestamp'] < end_time)]\n",
    "\n",
    "        event_counts1 = np.zeros((xx, yy), dtype=np.uint32)\n",
    "        event_counts0 = np.zeros((xx, yy), dtype=np.uint32)\n",
    "\n",
    "        positive_indices = time_filtered_events['polarity'] == 1\n",
    "        negative_indices = time_filtered_events['polarity'] == 0\n",
    "\n",
    "        np.add.at(event_counts1, (time_filtered_events[positive_indices]['y'], time_filtered_events[positive_indices]['x']), 1)\n",
    "\n",
    "        np.add.at(event_counts0, (time_filtered_events[negative_indices]['y'], time_filtered_events[negative_indices]['x']), 1)\n",
    "\n",
    "        event_counts_diff = event_counts1 - event_counts0\n",
    "        image = np.where(event_counts_diff > 1, 255, 0).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        save_path = os.path.join(folder_path.replace('700_700_npy_dev', '700_700_frame_dev'), f\"{file[:-4]}_{i}.png\")\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        image.save(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raw to png (KTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from metavision_core.event_io import AdaptiveRateEventsIterator\n",
    "from metavision_core.event_io import EventsIterator\n",
    "from metavision_sdk_core import AdaptiveRateEventsSplitterAlgorithm\n",
    "\n",
    "sys.path.append(r\"C:\\\\Program Files\\\\Prophesee\\\\lib\\\\python3\\\\site-packages\\\\\")\n",
    "sys.path.append(os.path.dirname(r\"C:\\\\Program Files\\\\Prophesee\\\\share\\\\metavision\\\\sdk\\\\core\\\\python_samples\\\\metavision_adaptive_rate\"))\n",
    "\n",
    "\n",
    "\n",
    "def events_to_diff_image(events, sensor_size, strict_coord=True):\n",
    "    xs = events[\"x\"]\n",
    "    ys = events[\"y\"]\n",
    "    ps = events[\"p\"] # ps = 0/1(-/+)\n",
    "\n",
    "    # Filter out events outside the size of the sensor\n",
    "    mask = (xs < sensor_size[1]) * (ys < sensor_size[0]) * (xs >= 0) * (ys >= 0)\n",
    "\n",
    "    if strict_coord:\n",
    "        assert (mask == 1).all()\n",
    "    coords = np.stack((ys*mask, xs*mask))\n",
    "    ps *= mask\n",
    "   \n",
    "\n",
    "    try:\n",
    "        abs_coords = np.ravel_multi_index(coords, sensor_size)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Issue with input arrays! coords={}, min_x={}, min_y={}, max_x={}, max_y={}, coords.shape={}, sum(coords)={}, sensor_size={}\".format(\n",
    "            coords, min(xs), min(ys), max(xs), max(ys), coords.shape, np.sum(coords), sensor_size))\n",
    "\n",
    "    img = np.bincount(abs_coords, weights=ps, minlength=sensor_size[0]*sensor_size[1])\n",
    "    img = img.reshape(sensor_size)\n",
    "    return img\n",
    "\n",
    "\n",
    "# Config\n",
    "delta_t = 1000000\n",
    "output_dir = \"D:\\\\project\\\\KTH\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "timeline_data_path = 'D:/project/dev_timeline.npy'\n",
    "timeline_data = np.load(timeline_data_path, allow_pickle=True)\n",
    "file_start_times = {row[0]: (float(row[1]), float(row[2])) for row in timeline_data}\n",
    "first_frame = float(timeline_data[0][1])\n",
    "\n",
    "# raw_file_path = \"D:\\\\project\\\\KTH\\\\test_output\\\\train.raw\"\n",
    "raw_file_path = \"C:\\\\Users\\\\soapy\\\\Documents\\\\metavision\\\\recordings\\\\dev.raw\"\n",
    "\n",
    "# Initialization\n",
    "events_iterator = EventsIterator(raw_file_path, mode=\"delta_t\", delta_t=delta_t)\n",
    "height, width = events_iterator.get_size()\n",
    "\n",
    "\n",
    "frame_indices = {name: 0 for name in file_start_times}\n",
    "for frame_index, events in enumerate(events_iterator):\n",
    "    current_ts = frame_index * delta_t - first_frame * 1e6  \n",
    "\n",
    "    # Check which video segment the current event data belongs to\n",
    "    for file_name, (start_t, end_t) in file_start_times.items():\n",
    "        start_ts_true = (start_t - first_frame) * 1e6  \n",
    "        end_ts_true = (end_t - first_frame) * 1e6 \n",
    "\n",
    "        if start_ts_true <= current_ts <= end_ts_true:\n",
    "            base_file_name = file_name.replace(\".mp4\", \"\")\n",
    "            true_frame_index = frame_indices[file_name]\n",
    "            image_filename = f\"{base_file_name}_{true_frame_index}.png\"\n",
    "            img = events_to_diff_image(events, sensor_size=(height, width))\n",
    "            img = np.where(img > 1, 255, 0)  # Threshold\n",
    "            plt.imsave(os.path.join(output_dir, image_filename), img, cmap='gray')\n",
    "            print(f\"Saved {image_filename} for timeslot {file_name}\")\n",
    "            frame_indices[file_name] += 1  \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# png resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "src_folder = \"D:/project/KTH/match_data/dev_origin\"\n",
    "dest_folder = \"D:/project/KTH/match_data/dev\"\n",
    "\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_folder):\n",
    "    if filename.lower().endswith('.png'):  \n",
    "        img_path = os.path.join(src_folder, filename)\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        new_width = int(img.width * 0.75)\n",
    "        new_height = int(img.height * 0.75)\n",
    "        \n",
    "        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS) \n",
    "        \n",
    "\n",
    "        new_img = Image.new('RGB', (500, 500), (0, 0, 0))\n",
    "        x = (500 - new_width) // 2\n",
    "        y = (500 - new_height) // 2\n",
    "        \n",
    "\n",
    "        new_img.paste(img_resized, (x, y))\n",
    "        new_img.save(os.path.join(dest_folder, filename))\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# png rename and produce npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "label_map = {'boxing': 0, 'handclapping': 1, 'handwaving': 2, 'jogging': 3, 'running': 4, 'walking': 5}\n",
    "\n",
    "def preprocess_images(root_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    labels_txt = []  # To store numeric labels for txt file\n",
    "    details_list = []  # To store the image details including person, activity, day, sequence, numeric label for npy, image counter, and concatenated label\n",
    "    image_counter = 0  # To name images sequentially\n",
    "\n",
    "    for filename in os.listdir(root_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) == 5:  # Expected format: person01_boxing_d2_uncomp_10.png\n",
    "                person = parts[0]\n",
    "                activity = parts[1]\n",
    "                day = parts[2]\n",
    "                sequence_number = parts[4].split('.')[0]  # Remove the '.png'\n",
    "                \n",
    "                if activity in label_map:\n",
    "                    # Convert string label to numeric label for txt file\n",
    "                    numeric_label_txt = label_map[activity]\n",
    "                    # Convert string label to numeric label for npy file\n",
    "                    numeric_label_npy = label_map[activity]\n",
    "\n",
    "                    # Construct the concatenated label\n",
    "                    concatenated_label = f\"{person}_{activity}_{day}_uncomp\"\n",
    "\n",
    "                    # Read and process image\n",
    "                    file_path = os.path.join(root_dir, filename)\n",
    "                    with Image.open(file_path) as img:\n",
    "                        # Save processed image with a new sequential name\n",
    "                        output_filename = f'image_{image_counter}.png'\n",
    "                        output_path = os.path.join(output_dir, output_filename)\n",
    "                        img.save(output_path)  # Directly save the original image under new name\n",
    "                        \n",
    "                        # Append details to list including the image counter and concatenated label\n",
    "                        details_list.append([person, activity, day, sequence_number, numeric_label_npy, image_counter, concatenated_label])\n",
    "                        \n",
    "                        # Append numeric label for text file (1-6)\n",
    "                        labels_txt.append(numeric_label_txt)\n",
    "                        \n",
    "                        # Increment image counter\n",
    "                        image_counter += 1\n",
    "\n",
    "    # Convert list to numpy array and save\n",
    "    details_array = np.array(details_list, dtype='U50')  \n",
    "    np.save(os.path.join(output_dir, 'bhh-jrw_dev.npy'), details_array)\n",
    "\n",
    "    # Save labels to a text file\n",
    "    with open(os.path.join(output_dir, 'labels.txt'), 'w') as f:\n",
    "        for label in labels_txt:\n",
    "            f.write(f\"{label}\\n\")\n",
    "\n",
    "# Specify the output directory and input directory\n",
    "output_train_dir = 'D:/project/KTH/match_data/KTH_dev_rebal'\n",
    "preprocess_images('D:/project/KTH/match_data/KTH_dev', output_train_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creat hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_folder = r'D:/project/KTH/match_data/KTH_dev_rebal'\n",
    "label_file = r'D:/project/KTH/match_data/KTH_dev_rebal/labels.txt'\n",
    "\n",
    "\n",
    "with open(label_file, 'r') as f:\n",
    "    labels = f.readlines()\n",
    "labels = [int(label.strip()) for label in labels]\n",
    "\n",
    "hdf5_file = 'D:/project/KTH/match_data/dev.hdf5'\n",
    "with h5py.File(hdf5_file, 'w') as f:\n",
    "    num_images = len(labels)\n",
    "    image_shape = (num_images, 500, 500) \n",
    "    label_shape = (num_images,)\n",
    "\n",
    "    images_dset = f.create_dataset('images', shape=image_shape, dtype=np.uint8)\n",
    "    labels_dset = f.create_dataset('labels', shape=label_shape, dtype=np.uint8)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image_path = f'{image_folder}/image_{i}.png'\n",
    "        image = Image.open(image_path).convert('L')  \n",
    "        \n",
    "        image_array = np.array(image)\n",
    "        images_dset[i] = image_array\n",
    "\n",
    "        labels_dset[i] = labels[i]  \n",
    "\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
